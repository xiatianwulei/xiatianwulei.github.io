---
layout:     post
title:      UI绘制原理和渲染过程
subtitle:   
date:       2019-12-20
author:     夏天无泪
header-img: img/post-bg-android.jpg?raw=true
catalog: true
tags:
    - 学习整理
---

# UI 的绘制原理 
  
## 图形绘制原理    
 
### 一、CPU与GPU分别做了什么?  

#### 概述  

**可视化应用程序都是由 CPU 和 GPU 协作执行的.**  

 **CPU** 内部采用的是流水线结构, 使其拥有一定程度的并行计算能力.   
 **GPU** 是一种可进行绘图运算工作的专用微处理器, 是一个被高度优化设计的用来并发计算的硬件单元. 硬件设计的模式差异就决定了两者在图像显示中的不同定位.  
 **CPU**擅长分支预测等复杂操作, GPU擅长对大量数据进行简单操作. 一个是复杂的劳动, 一个是大量并行的工作. 其实GPU可以看作是一种专用的CPU, 专为单指令在大块数据上工作而设计, 这些数据都是进行相同的操作.  

#### 1. **渲染**  

图像想显示到屏幕上使人肉眼可见都需借助像素的力量. 简单地说, 每个像素由红，绿，蓝三种颜色组成, 它们密集的排布在手机屏幕上, 将任何图形通过不同的色值表现出来. 计算机显示的流程大致可以描述为将图像转化为一系列像素点的排列然后打印在屏幕上. **计算机将存储在内存中的形状转换成实际绘制在屏幕上的对应的过程称为渲染**. 渲染过程中最常用的技术就是光栅化, 光栅化就是从矢量的点线面的描述, 变成像素的描述.

#### 2. **CPU要做的工作**  

1. Layout: 这里主要涉及到一些UI布局，文本计算等，例如一个label的size  
2. Display: 绘制阶段（drawRect），例如drawRect方法就在这一步骤中
3. Prepare: 图片的编解码等操作在此步骤中
4. Commit: 提交位图  

#### 3. **GPU 图形渲染流水线**  

GPU 图形渲染流水线的主要工作可以被划分为两个部分:

* 把 3D 坐标转换为 2D 坐标
* 把 2D 坐标转变为实际的有颜色的像素

**GPU 图形渲染流水线的具体实现可分为六个阶段，如下图所示**  

* 顶点着色（Vertex Shader）
* 形状装配（Shape Assembly），又称 图元装配
*  几何着色器（Geometry Shader）
* 光栅化（Rasterization）
* 片段着色（Fragment Shader）
* 片段处理（Tests and Blending）

![OpenGL渲染示意图](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/opengl-graphics-pipeline.png?raw=true)

#### 4.CPU-GPU 异构系统 

![CPU-GPU 异构系统](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/cpu-gpu-architecture.png?raw=true)  

左图是**分离式的结构**，CPU 和 GPU 拥有各自的存储系统，两者通过 PCI-e 总线进行连接。这种结构的缺点在于 PCI-e 相对于两者具有低带宽和高延迟，数据的传输成了其中的性能瓶颈。目前使用非常广泛，如PC、智能手机等。

右图是**耦合式的结构**，CPU 和 GPU 共享内存和缓存。AMD 的 APU 采用的就是这种结构，目前主要使用在游戏主机中，如 PS4。

在存储管理方面，分离式结构中 CPU 和 GPU 各自拥有独立的内存，两者共享一套虚拟地址空间，必要时会进行内存拷贝。对于耦合式结构，GPU 没有独立的内存，与 GPU 共享系统内存，由 MMU 进行存储管理。

图形应用程序调用 OpenGL 或 Direct3D API 功能，将 GPU 作为协处理器使用。API 通过面向特殊 GPU 优化的图形设备驱动向 GPU 发送命令、程序、数据。  

#### 5.CPU-GPU 工作流  

CPU-GPU 异构系统的工作流, 当 CPU 遇到图像处理的需求时，会调用 GPU 进行处理，主要流程可以分为以下四步:  

1. 将主存的处理数据复制到显存中
2. CPU 指令驱动 GPU
3. GPU 中的每个运算单元并行处理
4. GPU 将显存结果传回主存

**这篇文章讲解的非常详细[渲染过程中硬件（GPU）](http://chuquan.me/2018/08/26/graphics-rending-principle-gpu/)  ,感兴趣的同学可以看看**

## 图像显示原理  

### 一、屏幕图像显示原理

图像想显示到屏幕上使人肉眼可见都需借助像素的力量. 简单地说, 每个像素由红，绿，蓝三种颜色组成, 它们密集的排布在手机屏幕上, 将任何图形通过不同的色值表现出来. 计算机显示的流程大致可以描述为将图像转化为一系列像素点的排列然后打印在屏幕上.  

![屏幕图像显示原理](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/ios-screen-scan.png?raw=true)    

介绍屏幕图像显示的原理，需要先从 CRT 显示器原理说起，如上图所示。CRT 的电子枪从上到下逐行扫描，扫描完成后显示器就呈现一帧画面。然后电子枪回到初始位置进行下一次扫描。为了同步显示器的显示过程和系统的视频控制器，显示器会用硬件时钟产生一系列的定时信号。当电子枪换行进行扫描时，显示器会发出一个**水平同步信号**（horizonal synchronization），简称 HSync；而当一帧画面绘制完成后，电子枪回复到原位，准备画下一帧前，显示器会发出一个**垂直同步信号**（vertical synchronization），简称 VSync。显示器通常以固定频率进行刷新，这个刷新率就是 VSync 信号产生的频率。虽然现在的显示器基本都是液晶显示屏了，但其原理基本一致, 如上图所示:  

### 二、CPU、GPU、显示器工作方式  

![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/ios_screen_display.png?raw=true)  

**概述**：CPU与GPU是通过总线连接起来，通过CPU输出一个位图，经由总线传输在合适的时机上传到GPU，GPU获取到位图后，会进行图层渲染、纹理合成，将结果放入帧缓存区中缓冲区，有两块缓冲区，前帧缓存和后帧缓存，协调使用，效率高），由视频控制器根据VSyn信号，在指定时间之前提取帧缓存区中的屏幕显示内容，最终显示到手机屏幕上。    
    
   **简单概括** 
 >CPU 计算数据 -> GPU 进行渲染 -> 渲染结果存入帧缓冲区 -> 视频控制器会按照 VSync 信号逐帧读取帧缓冲区的数据 -> 成像  
 
 创建UIView后，显示部分由CALayer负责，CALayer有一个contents属性，就是我们最终要绘制到屏幕上的位图，如果我们创建的是UILabel，那么contents上最终要绘制就是“Hello”的位图,系统在合适的时候回调给我们一个drawRect的方法，然后我们可以在此基础上绘制一些我们想自定义绘制的内容，绘制好的这个位图，会经过Core Animation提交给GPU部分的OpenGL渲染管线，进行最终的位图的渲染以及文理的合成，最终显示到屏幕上。

![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/display_sepereate.png?raw=true)  

## iOS图像渲染原理  

这里主要介绍 iOS 开发过程中图形渲染原理. 首先介绍几个概念.   

>   UIKit Framework 正如Apple官方文档对UIKit Framework的介绍，它主要提供了：界面呈现能力、事件响应能力、驱动RunLoop运行和与系统内核通信的数据。简单来说就是：**主要负责界面展示、事件响应以及是RunLoop的需求方。UIView当然是属于UIKit Framework。**  

>QuartzCore（kwôrts） Framework 与 CoreAnimation 正如Apple官方文档对Quarz Core Framework的介绍，**它提供了图形处理和视频图像处理的能力。**简单来说就是：QuartzCore Framework负责把图形图像最终显示到屏幕上，这里我觉得应该是特指CoreAnimation。不要从字面上去理解CoreAnimation的职责，因为它的核心工作不单是负责动画的创建和执行，它还负责把我们用代码构建的界面显示到屏幕上，实际上是CoreAnimation通过OpenGLES做的。（别急，虽然这里面的机理很复杂，但是在后面会提到）。CALayer是属于QuarzCore Framework下的CoreAnimation

>CoreGraphics（ˈgrafik） Framework 如Apple官方文档对Core Graphics Framework的介绍。**CoreGraphics Framework一个基于C库函数的高级绘画引擎，它提供了非常强大的轻量级2D渲染能力。**可以使用CoreGraphics处理基于path的绘图工作(如，CGPath)、变形操作(如，CGAffineTransform)、颜色管理(如，CGColor)、离屏渲染(如，CGBitmapContextCreateImage)、渲染模式(patterns)、渐变(gradients)、阴影效果、图形数据管理、图形创建、蒙版以及PDF文档的创建、显示和解析。 千万别和QuartzCore混淆，CoreGraphics负责创建显示到屏幕上的数据模型，QuartzCore(CoreAnimation –> OpenGLES)负责把CoreGraphics创建的数据模型真正显示到屏幕上。 CG打头的类都是属于CoreGraphics Framework

以上三者的关系 三者的关系是通过界面展示以及动画的创建、执行关联起来的，所以它们之间是协作而不是从属的关系。在接下来的部分我会从几个方面来阐述以上几个Framework是怎样游游走与UIView与CALayer之间的  

![APP 绘制流程](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/ios-rendering-framework-relationship.png?raw=true)  

App 使用 Core Graphics、Core Animation、Core Image 等框架来绘制可视化内容，这些软件框架相互之间也有着依赖关系。这些框架都需要通过 OpenGL（开放式图形库） 来调用 GPU 进行绘制，最终将内容显示到屏幕之上.

### 一、UIView的绘制原理  

当调用UIView的`setNeedsDisplay`方法时，其实并没有立即进行绘制工作，会调用`CALayer`的同名方法`setNeedsDisplay`,这时并没有立即发生绘制，而只是相当于在当前`layer`打上了标记,会在`Runloop`即将结束时才会调`[CALayer display]`然后进入我们视图的真正绘制过程。  

而在`[CALayer display]`这个方法的内部实现中会判断这个layer的delegate是否响应`displayLayer:`这个方法，如果不响应这个方法，就会进入到**系统绘制**流程中；如果响应这个方法，那么就会为我们提供**异步绘制**的入口 

![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/display_flow.png?raw=true)  

#### 1. 系统绘制实现  

1) 在CALayer内部会先创建backing store，我可以理解为CGContext，我们一般在drawRect:方法中通过上下文堆栈当中取出栈顶的context,也就是上下文.  

2). 然后这个layer会判断是否有代理，如果没有代理，那么就会调用`[CALayer drawInContext:]`；如果有代理，会调用代理的`drawLayer:inContext:`方法，然后做当前视图的绘制工作（这一步是发生在系统内部的），然后在一个合适的时机给与我们这个十分熟悉的`[UIView drawRect:]`方法的回调，`[UIView drawRect:]`这个方法默认是什么都不做，，系统给我们开这个口子是为了让我们可以再做一些其他的绘制工作

3).  然后无论是哪个分支，最终都会由CALayer上传对应的backing store(可以理解为位图)给GPU，然后就结束了系统默认的绘制流程


![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/system_display_new.png?raw=true)  

#### 2. 异步绘制实现  

我们需要通过实现layer的代理方法`displayLayer`    

* 在这个异步绘制过程中,代理负责生成对应的bitmap(位图)
* 同时设置bitmap作为layer.contents属性的值    

![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/asyn_display.png?raw=true)  

* 假如说我们在某一个时机调用了`[view setNeedsDisplay]`这个方法，系统会在当前runloop将要结束的时候调用`[CALyer display]`方法，然后如果我们这个layer的代理实现了[view displayLayer]这个方法  
* 然后会通过子线程的切换，我们在子线程中去做一个位图的绘制，主线程可以去做一些其他的操作
* 在子线程中第一步先通过`CGBitmapContextCreate()`方法来创建一个位图的上下文，然后我们通过CoreGraphic API可以做当前UI控件的一些绘制工作，最后我们再通过`CGBitmapContextCreateImage()`这个函数来根据当前所绘制的上下文来生成一张CGImage图片
* 最后回到主线程来提交这个位图，设置layer的contents属性，这样就完成了一个UI控件的异步绘制过程

#### 3.离屏渲染（便于理解视图卡顿、掉帧中对GPU的开销）  

**离屏渲染指的是:GPU在当前屏幕缓冲区以外开辟了一个缓冲区进行渲染操作**    

当前屏幕渲染不需要额外创建新的缓存，也不需要开启新的上下文，相对于离屏渲染性能更好。但是受当前屏幕渲染的局限因素限制(只有自身上下文、屏幕缓存有限等)，当前屏幕渲染有些情况下的渲染解决不了的，就使用到离屏渲染

On-Screen Rendering 意为当前屏幕渲染，指的是GPU的渲染操作是在当前用于显示的屏幕缓冲区中进行渲染操作  

Off-Screen Rendering 意为离屏渲染，指的是GPU在当前屏幕缓冲区以外新开辟一个缓冲区进行渲染操作  

**当设置某些UI视图的图层属性，如果标记为未合成之前不能用于显示，那么就会触发离屏渲染**

触发离屏渲染的条件

* 圆角（和maskToBounds一起使用时）
* 图层蒙版(masks)
* 阴影(shadows)
* 光栅化 (shouldRasterize)
* 渐变
* 不透明(group opacity)

离屏渲染对性能的的代价是很高的，主要体现在：  

* 创建了新的缓冲区
* 上下文的频繁切换

**触发离屏渲染，增加GPU工作量，而GPU的工作的增加可能导致CPU+GPU产生一帧画面的时间超过16.7ms，就会产生卡顿掉帧，所以要避免离屏渲染。**  

#### 4.View绘制渲染机制和Runloop的关系  

当操作了UI，如改变frame、更新UIView或CALayer的层次、手动调用`setNeedsLayout`/`setNeedsDisplay`方法后，这个UIView/CAlayer就被标记成待处理，并被提交到一个全局的容器中。

在Runloop中，系统注册了一个observer来监听BeforeWaiting（即将休眠）和Exit（即将退出Runloop）事件，回调去执行一个函数，这个函数会遍历所有待处理的UIView/CALayer以执行实际的绘制和调整，并更新界面。  
·
具体为：observer检查函数 ->检查图层树中有没有待处理的对象 ->如果没有则runloop休眠 ->有则CPU更新图层树，交给Core Animation运走 ->Core Animation把待处理的图层对象，通过IPC发送给渲染进程 ->GPU开始渲染》发送到缓冲区 ->展示view



![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/677071-0bb9dd062eb39699.png?raw=true)    

从上图中可以看到  

runloop的observer回调 => CoreAnimation渲染引擎一次事务的提交=>CoreAnimation递归查询图层是否有布局上的更新=>`CALayer layoutSublayers`=>`UIView layoutSubviews` 这样一个调用的流程。从这里也可以看到UIView其实就是相当于CALayer的代理。


**刷新视图补充:**  
`layoutSubviews`只有当子视图的自动调整、约束的行为不能满足你时，你才应该重写此方法.    

`setNeedsLayout`这个方法**标记**为需要重新布局，异步调用`layoutIfNeeded`刷新布局，不立即刷新，但`layoutSubviews`一定会被调用。  

`layoutIfNeeded`方法：如果有需要刷新的标记，立即调用`layoutSubviews`进行布局（如果没有标记，不会调用`layoutSubviews`）  

> 在视图第一次显示之前，标记肯定是“需要刷新”的，所以直接调用`view.layoutIfNeeded()`就会进行立即更新。  
> 如果要在当前runloop立即刷新，要先调用`view.setNeedsLayout()`，把标记设为需要布局，然后马上调用`view.layoutIfNeeded`，实现布局。  

**只要知道什么时候调用`layoutIfNeeded`[stackoverflow解答](https://stackoverflow.com/questions/1182945/how-is-layoutifneeded-used)**，其余情况调用`setNeedsLayout `来优化性能。  
同时[`UIview需要知道的一些事情：setNeedsDisplay、setNeedsLayout`](https://www.jianshu.com/p/64ecfbc01536)。


### 二、图像显示原理 和 卡顿产生的原因 

**帧缓冲 & 垂直同步**  

最简单的情况下，帧缓冲区只有一个。此时，帧缓冲区的读取和刷新都都会有比较大的效率问题。为了解决效率问题，GPU 通常会引入两个缓冲区，即 双缓冲机制。在这种情况下，GPU 会预先渲染一帧放入一个缓冲区中，用于视频控制器的读取。当下一帧渲染完毕后，GPU 会直接把视频控制器的指针指向第二个缓冲器。  

双缓冲虽然能解决效率问题，但会引入一个新的问题。当视频控制器还未读取完成时，即屏幕内容刚显示一半时，GPU 将新的一帧内容提交到帧缓冲区并把两个缓冲区进行交换后，视频控制器就会把新的一帧数据的下半段显示到屏幕上，造成画面撕裂现象，如下图：

![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/ios-vsync-off.png?raw=true)  



![](https://github.com/xiatianwulei/xiatianwulei.github.io/blob/master/img/media//UIVivew渲染和卡顿/ios_frame_drop.png?raw=true)  

**一帧（或一页）数据就是**：  
一个垂直同步信号（VSync ）和一个水平同步信号（HSync）的组合。先发送一个垂直同步信号（VSync ），代表即将显示一页，再发送一个水平同步信号（HSync）就显示一帧。如果当下一次VSync信号到来之前，CPU和GPU还没有计算完成，就会产生卡顿。

**卡顿产生的原因**：  
在 VSync 信号到来后，系统图形服务会通过 CADisplayLink 等机制通知 App，App 主线程开始在 CPU 中计算显示内容，比如视图的创建、布局计算、图片解码、文本绘制等。随后 CPU 会将计算好的内容提交到 GPU 去，由 GPU 进行变换、合成、渲染。随后 GPU 会把渲染结果提交到帧缓冲区去，等待下一次 VSync 信号到来时显示到屏幕上。由于垂直同步的机制，如果在一个 VSync 时间内，CPU 或者 GPU 没有完成内容提交，则那一帧就会被丢弃，等待下一次机会再显示，而这时显示屏会保留之前的内容不变。**这就是界面卡顿的原因。**  

**结论：**  
从上面的图中可以看到，CPU 和 GPU 不论哪个阻碍了显示流程，都会造成掉帧现象。所以开发时，也需要分别对 CPU 和 GPU 压力进行评估和优化
